---
category: doc
tags: [homework]
---

### í…ì„œ
**í…ì„œë€?**
ì¼ê´€ëœ ìœ í˜•(dtypeì´ë¼ê³  ë¶ˆë¦¼)ì„ ê°€ì§„ ë‹¤ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ëª¨ë“  dtypesì€ tf.dtypes.DTypeì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
ì‰½ê²Œ ë§í•´ í…ì„œëŠ” **'ê¸°ë³¸ì ìœ¼ë¡œ ìˆ«ìë¥¼ ë‹´ì€ ì»¨í…Œì´ë„ˆ'** ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤

### ìŠ¤ì¹¼ë¼

'ìŠ¤ì¹¼ë¼' ë˜ëŠ” 'ìˆœìœ„-0' í…ì„œëŠ” ë‹¨ì¼ ê°’ì„ í¬í•¨í•˜ë©° "ì¶•"ì€ ì—†ìŠµë‹ˆë‹¤.
ì•„ë˜ëŠ” ìŠ¤ì¹¼ë¼ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.

```
# This will be an int32 tensor by default; see "dtypes" below.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(4, shape=(), dtype=int32)
```

### ë²¡í„°

'ë²¡í„°' ë˜ëŠ” 'ìˆœìœ„-1' í…ì„œëŠ” ê°’ì˜ ëª©ë¡ê³¼ ê°™ìŠµë‹ˆë‹¤. ë²¡í„°ì—ëŠ” í•˜ë‚˜ì˜ ì¶•ì´ ìˆìŠµë‹ˆë‹¤.
ì‰½ê²Œ ì •ë¦¬í•˜ìë©´ **'1ê°œì˜ ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ëœ í…ì„œë¡œ í‘œí˜„'** ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.
ì•„ë˜ëŠ” ë²¡í„°ì˜ ì˜ˆì‹œì½”ë“œì…ë‹ˆë‹¤.

```
# Let's make this a float tensor.
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
```

### í–‰ë ¬
'í–‰ë ¬' ë˜ëŠ” 'ìˆœìœ„-2' í…ì„œì—ëŠ” ë‘ ê°œì˜ ì¶•ì´ ìˆìŠµë‹ˆë‹¤.
ì‰½ê²Œ ì •ë¦¬í•˜ìë©´ **'2ê°œì˜ ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ëœ í…ì„œë¡œ í‘œí˜„'**ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤.
ì•„ë˜ëŠ” í–‰ë ¬ì˜ ì˜ˆì‹œì½”ë“œì…ë‹ˆë‹¤.
```
# If we want to be specific, we can set the dtype (see below) at creation time
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(
[[1. 2.]
 [3. 4.]
 [5. 6.]], shape=(3, 2), dtype=float16)
```

í…ì„œì—ëŠ” ë” ë§ì€ ì¶•ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì„¸ ê°œì˜ ì¶•ì´ ìˆëŠ” í…ì„œê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
```
# There can be an arbitrary number of
# axes (sometimes called "dimensions")
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

np.array ë˜ëŠ” tensor.numpy ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
np.array(rank_2_tensor)
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```
   
```
rank_2_tensor.numpy()
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

í…ì„œì—ëŠ” ì¢…ì¢… floatì™€ intê°€ í¬í•¨ë˜ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ë¥¸ ìœ í˜•ë„ ìˆìŠµë‹ˆë‹¤.
* ë³µì†Œìˆ˜
* ë¬¸ìì—´

ê¸°ë³¸ tf.Tensor í´ë˜ìŠ¤ì—ì„œëŠ” í…ì„œê°€ "ì§ì‚¬ê°í˜•"ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì¦‰, ê° ì¶•ì„ ë”°ë¼ ëª¨ë“  ìš”ì†Œì˜ í¬ê¸°ê°€ ê°™ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¤ì–‘í•œ í˜•ìƒì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ ìœ í˜•ì˜ í…ì„œê°€ ìˆìŠµë‹ˆë‹¤.
* ë¹„ì •í˜•
* í¬ì†Œ

ë§ì…ˆ, ìš”ì†Œë³„ ê³±ì…ˆ ë° í–‰ë ¬ ê³±ì…ˆì„ í¬í•¨í•˜ì—¬ í…ì„œì— ëŒ€í•œ ê¸°ë³¸ ì‚°ìˆ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2])`

print(tf.add(a, b), "\n")
print(tf.multiply(a, b), "\n")
print(tf.matmul(a, b), "\n")
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32)

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

```
print(a + b, "\n") # element-wise addition
print(a * b, "\n") # element-wise multiplication
print(a @ b, "\n") # matrix multiplication
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32)

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

í…ì„œëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ì—°ì‚°(ops)ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
```
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
# Find the index of the largest value
print(tf.argmax(c))
# Compute the softmax
print(tf.nn.softmax(c))
```

**â†‘ ì½”ë“œ / ê²°ê³¼ â†“**
```
tf.Tensor(10.0, shape=(), dtype=float32)
tf.Tensor([1 0], shape=(2,), dtype=int64)
tf.Tensor(
[[2.6894143e-01 7.3105854e-01]
 [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
```

### í˜•ìƒ ì •ë³´
í…ì„œëŠ” í˜•ìƒì´ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ë˜ëŠ” ì¼ë¶€ ìš©ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤
* í˜•ìƒ: í…ì„œì˜ ê° ì°¨ì›ì˜ ê¸¸ì´(ìš”ì†Œì˜ ìˆ˜)
* ìˆœìœ„: í…ì„œ ì¶•ì˜ ìˆ˜ì…ë‹ˆë‹¤. ìŠ¤ì¹¼ë¼ëŠ” ìˆœìœ„ê°€ 0ì´ê³  ë²¡í„°ì˜ ìˆœìœ„ëŠ” 1ì´ë©° í–‰ë ¬ì˜ ìˆœìœ„ëŠ” 2ì…ë‹ˆë‹¤.
* ì¶• ë˜ëŠ” ì°¨ì›: í…ì„œì˜ íŠ¹ì • ì°¨ì›
* í¬ê¸°: í…ì„œì˜ ì´ í•­ëª© ìˆ˜, ê³± í˜•ìƒ ë²¡í„°

í…ì„œ ë° tf.TensorShape ê°ì²´ì—ëŠ” ë‹¤ìŒì— ì•¡ì„¸ìŠ¤í•˜ê¸° ìœ„í•œ í¸ë¦¬í•œ ì†ì„±ì´ ìˆìŠµë‹ˆë‹¤.
```
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

```
print("Type of every element:", rank_4_tensor.dtype)
print("Number of dimensions:", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())
```

ì¶•ì€ ì¢…ì¢… ì¸ë±ìŠ¤ë¡œ ì°¸ì¡°í•˜ì§€ë§Œ, í•­ìƒ ê° ì¶•ì˜ ì˜ë¯¸ë¥¼ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤. ì¶•ì´ ì „ì—­ì—ì„œ ë¡œì»¬ë¡œ ì •ë ¬ë˜ëŠ” ê²½ìš°ê°€ ì¢…ì¢… ìˆìŠµë‹ˆë‹¤. ë°°ì¹˜ ì¶•ì´ ë¨¼ì € ì˜¤ê³  ê·¸ ë‹¤ìŒì— ê³µê°„ ì°¨ì›ê³¼ ê° ìœ„ì¹˜ì˜ íŠ¹ì„±ì´ ë§ˆì§€ë§‰ì— ì˜µë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ íŠ¹ì„± ë²¡í„°ëŠ” ì—°ì†ì ì¸ ë©”ëª¨ë¦¬ ì˜ì—­ì…ë‹ˆë‹¤.

### ì¸ë±ì‹±
#### ë‹¨ì¼ ì¶• ì¸ë±ì‹±
TensorFlowëŠ” íŒŒì´ì¬ì˜ ëª©ë¡ ë˜ëŠ” ë¬¸ìì—´ ì¸ë±ì‹±ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ í‘œì¤€ íŒŒì´ì¬ ì¸ë±ì‹± ê·œì¹™ê³¼ numpy ì¸ë±ì‹±ì˜ ê¸°ë³¸ ê·œì¹™ì„ ë”°ë¦…ë‹ˆë‹¤.
* ì¸ë±ìŠ¤ëŠ” 0ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤.
* ìŒìˆ˜ ì¸ë±ìŠ¤ëŠ” ëì—ì„œë¶€í„° ê±°ê¾¸ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
* ì½œë¡ , :ì€ ìŠ¬ë¼ì´ìŠ¤ start:stop:stepì— ì‚¬ìš©ë©ë‹ˆë‹¤.

```
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
```

```
[ 0  1  1  2  3  5  8 13 21 34]
```

ìŠ¤ì¹¼ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë±ì‹±í•˜ë©´ ì¶•ì´ ì œê±°ë©ë‹ˆë‹¤.

```
print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())
```

```
First: 0
Second: 1
Last: 34
```

: ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë±ì‹±í•˜ë©´ ì¶•ì´ ìœ ì§€ë©ë‹ˆë‹¤.
```
print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())
```

```
Everything: [ 0  1  1  2  3  5  8 13 21 34]
Before 4: [0 1 1 2]
From 4 to the end: [ 3  5  8 13 21 34]
From 2, before 7: [1 2 3 5 8]
Every other item: [ 0  1  3  8 21]
Reversed: [34 21 13  8  5  3  2  1  1  0]
```

#### ë‹¤ì¶• ì¸ë±ì‹±
ë” ë†’ì€ ìˆœìœ„ì˜ í…ì„œëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¥¼ ì „ë‹¬í•˜ì—¬ ì¸ë±ì‹±ë©ë‹ˆë‹¤.

ë‹¨ì¼ ì¶•ì˜ ê²½ìš°ì—ì„œì™€ ì •í™•íˆ ê°™ì€ ê·œì¹™ì´ ê° ì¶•ì— ë…ë¦½ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.
```
print(rank_2_tensor.numpy())
```

```
[[1. 2.]
 [3. 4.]
 [5. 6.]]
```

ê° ì¸ë±ìŠ¤ì— ì •ìˆ˜ë¥¼ ì „ë‹¬í•˜ë©´ ê²°ê³¼ëŠ” ìŠ¤ì¹¼ë¼ì…ë‹ˆë‹¤.
```
# Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())
```

```
4.0
```

ì •ìˆ˜ì™€ ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì¡°í•©í•˜ì—¬ ì¸ë±ì‹±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
# Get row and column tensors
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")
```

```
Second row: [3. 4.]
Second column: [2. 4. 6.]
Last row: [5. 6.]
First item in last column: 2.0
Skip the first row:
[[3. 4.]
 [5. 6.]]
```

ë‹¤ìŒì€ 3ì¶• í…ì„œì˜ ì˜ˆì…ë‹ˆë‹¤.
```
print(rank_3_tensor[:, :, 4])
```

```
tf.Tensor(
[[ 4  9]
 [14 19]
 [24 29]], shape=(3, 2), dtype=int32)
```

### í˜•ìƒ ì¡°ì‘í•˜ê¸°
í…ì„œì˜ í˜•ìƒì„ ë°”ê¾¸ëŠ” ê²ƒì€ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.
```
# Shape returns a `TensorShape` object that shows the size on each dimension
var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
```

```
(3, 1)
```

```
# You can convert this object into a Python list, too
print(var_x.shape.as_list())
```

```
[3, 1]
```

í…ì„œë¥¼ ìƒˆë¡œìš´ í˜•ìƒìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë¥¼ ë³µì œí•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì¬êµ¬ì„±ì´ ë¹ ë¥´ê³  ì €ë ´í•©ë‹ˆë‹¤.
```
# We can reshape a tensor to a new shape.
# Note that we're passing in a list
reshaped = tf.reshape(var_x, [1, 3])
```

```
print(var_x.shape)
print(reshaped.shape)
```

```
(3, 1)
(1, 3)
```

ë°ì´í„°ì˜ ë ˆì´ì•„ì›ƒì€ ë©”ëª¨ë¦¬ì—ì„œ ìœ ì§€ë˜ê³  ìš”ì²­ëœ í˜•ìƒì´ ê°™ì€ ë°ì´í„°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ìƒˆ í…ì„œê°€ ì‘ì„±ë©ë‹ˆë‹¤. TensorFlowëŠ” C ìŠ¤íƒ€ì¼ "í–‰ ì¤‘ì‹¬" ë©”ëª¨ë¦¬ ìˆœì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ê°€ì¥ ì˜¤ë¥¸ìª½ì— ìˆëŠ” ì¸ë±ìŠ¤ë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ë©”ëª¨ë¦¬ì˜ ë‹¨ì¼ ë‹¨ê³„ì— í•´ë‹¹í•©ë‹ˆë‹¤.

```
print(rank_3_tensor)
```

```
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

í…ì„œë¥¼ í‰í‰í•˜ê²Œ í•˜ë©´ ì–´ë–¤ ìˆœì„œë¡œ ë©”ëª¨ë¦¬ì— ë°°ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
# A `-1` passed in the `shape` argument says "Whatever fits".
print(tf.reshape(rank_3_tensor, [-1]))
```

```
tf.Tensor(
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29], shape=(30,), dtype=int32)
```

ì¼ë°˜ì ìœ¼ë¡œ, tf.reshapeì˜ í•©ë¦¬ì ì¸ ìš©ë„ëŠ” ì¸ì ‘í•œ ì¶•ì„ ê²°í•©í•˜ê±°ë‚˜ ë¶„í• í•˜ëŠ” ê²ƒë¿ì…ë‹ˆë‹¤(ë˜ëŠ” 1ì„ ì¶”ê°€/ì œê±°).

ì´ 3x2x5 í…ì„œì˜ ê²½ìš°, ìŠ¬ë¼ì´ìŠ¤ê°€ í˜¼í•©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ (3x2)x5 ë˜ëŠ” 3x (2x5)ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì…ë‹ˆë‹¤.

```
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n")
print(tf.reshape(rank_3_tensor, [3, -1]))
```

```
tf.Tensor(
[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]
 [15 16 17 18 19]
 [20 21 22 23 24]
 [25 26 27 28 29]], shape=(6, 5), dtype=int32) 

tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9]
 [10 11 12 13 14 15 16 17 18 19]
 [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)
```

í˜•ìƒì„ ë³€ê²½í•˜ë©´ ê°™ì€ ì´ ìš”ì†Œ ìˆ˜ë¥¼ ê°€ì§„ ìƒˆë¡œìš´ í˜•ìƒì— ëŒ€í•´ "ì‘ë™"í•˜ì§€ë§Œ, ì¶•ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì§€ ì•Šìœ¼ë©´ ë³„ë¡œ ì“¸ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤.

tf.reshapeì—ì„œ ì¶• êµí™˜ì´ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´, tf.transposeë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

```
# Bad examples: don't do this

# You can't reorder axes with reshape.
print(tf.reshape(rank_3_tensor, [2, 3, 5]), "\n") 

# This is a mess
print(tf.reshape(rank_3_tensor, [5, 6]), "\n")

# This doesn't work at all
try:
  tf.reshape(rank_3_tensor, [7, -1])
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

```
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]
  [10 11 12 13 14]]

 [[15 16 17 18 19]
  [20 21 22 23 24]
  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)

tf.Tensor(
[[ 0  1  2  3  4  5]
 [ 6  7  8  9 10 11]
 [12 13 14 15 16 17]
 [18 19 20 21 22 23]
 [24 25 26 27 28 29]], shape=(5, 6), dtype=int32)

InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]
```

ì™„ì „íˆ ì§€ì •ë˜ì§€ ì•Šì€ í˜•ìƒ ì „ì²´ì— ê±¸ì³ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜•ìƒì— None(ì¶• ê¸¸ì´ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ)ì´ í¬í•¨ë˜ê±°ë‚˜ ì „ì²´ í˜•ìƒì´ None(í…ì„œì˜ ìˆœìœ„ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ)ì…ë‹ˆë‹¤.

### DTypesì— ëŒ€í•œ ì¶”ê°€ ì •ë³´
tf.Tensorì˜ ë°ì´í„° ìœ í˜•ì„ ê²€ì‚¬í•˜ë ¤ë©´, Tensor.dtype ì†ì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

Python ê°ì²´ì—ì„œ tf.Tensorë¥¼ ë§Œë“¤ ë•Œ ì„ íƒì ìœ¼ë¡œ ë°ì´í„° ìœ í˜•ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, TensorFlowëŠ” ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ë°ì´í„° ìœ í˜•ì„ ì„ íƒí•©ë‹ˆë‹¤. TensorFlowëŠ” Python ì •ìˆ˜ë¥¼ tf.int32ë¡œ, Python ë¶€ë™ ì†Œìˆ˜ì  ìˆ«ìë¥¼ tf.float32ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, TensorFlowëŠ” NumPyê°€ ë°°ì—´ë¡œ ë³€í™˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê·œì¹™ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ìœ í˜•ë³„ë¡œ ìºìŠ¤íŒ…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
# Now, let's cast to an uint8 and lose the decimal precision
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
```

```
tf.Tensor([2 3 4], shape=(3,), dtype=uint8)
```

### ë¸Œë¡œë“œìºìŠ¤íŒ…
ë¸Œë¡œë“œìºìŠ¤íŒ…ì€ NumPyì˜ í•´ë‹¹ íŠ¹ì„±ì—ì„œ ë¹Œë¦° ê°œë…ì…ë‹ˆë‹¤. ìš”ì»¨ëŒ€, íŠ¹ì • ì¡°ê±´ì—ì„œ ì‘ì€ í…ì„œëŠ” ê²°í•©ëœ ì—°ì‚°ì„ ì‹¤í–‰í•  ë•Œ ë” í° í…ì„œì— ë§ê²Œ ìë™ìœ¼ë¡œ "í™•ì¥(streched)"ë©ë‹ˆë‹¤.

ê°€ì¥ ê°„ë‹¨í•˜ê³  ê°€ì¥ ì¼ë°˜ì ì¸ ê²½ìš°ëŠ” ìŠ¤ì¹¼ë¼ì— í…ì„œë¥¼ ê³±í•˜ê±°ë‚˜ ì¶”ê°€í•˜ë ¤ê³  í•  ë•Œì…ë‹ˆë‹¤. ì´ ê²½ìš°, ìŠ¤ì¹¼ë¼ëŠ” ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ê°™ì€ í˜•ìƒìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ë©ë‹ˆë‹¤.
```
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```

```
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```

ë§ˆì°¬ê°€ì§€ë¡œ, í¬ê¸°ê°€ 1ì¸ ì¶•ì€ ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ì¸ìˆ˜ ëª¨ë‘ ê°™ì€ ê³„ì‚°ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ê²½ìš°, 3x1 í–‰ë ¬ì— ìš”ì†Œë³„ë¡œ 1x4 í–‰ë ¬ì„ ê³±í•˜ì—¬ 3x4 í–‰ë ¬ì„ ë§Œë“­ë‹ˆë‹¤. ì„ í–‰ 1ì´ ì„ íƒ ì‚¬í•­ì¸ ì ì— ìœ ì˜í•˜ì„¸ìš”. yì˜ í˜•ìƒì€ [4]ì…ë‹ˆë‹¤.

```
# These are the same computations
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))
```

```
tf.Tensor(
[[1]
 [2]
 [3]], shape=(3, 1), dtype=int32)

tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)

tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

ë¸Œë¡œë“œìºìŠ¤íŒ…ì´ ì—†ëŠ” ê°™ì€ ì—°ì‚°ì´ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤.

```
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # Again, operator overloading
```

```
tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë¸Œë¡œë“œìºìŠ¤íŒ…ì€ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì—°ì‚°ìœ¼ë¡œ ë©”ëª¨ë¦¬ì—ì„œ í™•ì¥ëœ í…ì„œë¥¼ êµ¬ì²´í™”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‹œê°„ê³¼ ê³µê°„ íš¨ìœ¨ì ì…ë‹ˆë‹¤.

tf.broadcast_toë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸Œë¡œë“œìºìŠ¤íŒ…ì´ ì–´ë–¤ ëª¨ìŠµì¸ì§€ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

```
tf.Tensor(
[[1 2 3]
 [1 2 3]
 [1 2 3]], shape=(3, 3), dtype=int32)
```

ì˜ˆë¥¼ ë“¤ì–´, broadcast_toëŠ” ìˆ˜í•™ì ì¸ opì™€ ë‹¬ë¦¬ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ íŠ¹ë³„í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ í…ì„œë¥¼ êµ¬ì²´í™”í•©ë‹ˆë‹¤.

í›¨ì”¬ ë” ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Jake VanderPlasì˜ ì €ì„œ Python Data Science Handbookì˜ í•´ë‹¹ ì„¹ì…˜ì—ì„œëŠ” ë” ë§ì€ ë¸Œë¡œë“œìºìŠ¤íŒ… íŠ¸ë¦­ì„ ë³´ì—¬ì¤ë‹ˆë‹¤(NumPyì—ì„œ).

### tf.convert_to_tensor
tf.matmul ë° tf.reshapeì™€ ê°™ì€ ëŒ€ë¶€ë¶„ì˜ opsëŠ” í´ë˜ìŠ¤ tf.Tensorì˜ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìœ„ì˜ ê²½ìš°, í…ì„œ í˜•ìƒì˜ Python ê°ì²´ê°€ ìˆ˜ìš©ë¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì „ë¶€ëŠ” ì•„ë‹ˆì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ opsëŠ” í…ì„œê°€ ì•„ë‹Œ ì¸ìˆ˜ì— ëŒ€í•´ convert_to_tensorë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ë³€í™˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ê°€ ìˆì–´ NumPyì˜ ndarray, TensorShape , Python ëª©ë¡ ë° tf.Variableê³¼ ê°™ì€ ëŒ€ë¶€ë¶„ì˜ ê°ì²´ í´ë˜ìŠ¤ëŠ” ëª¨ë‘ ìë™ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

ìì„¸í•œ ë‚´ìš©ì€ tf.register_tensor_conversion_functionì„ ì°¸ì¡°í•˜ì„¸ìš”. ìì‹ ë§Œì˜ ìœ í˜•ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ í…ì„œë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë¹„ì •í˜• í…ì„œ
ì–´ë–¤ ì¶•ì„ ë”°ë¼ ë‹¤ì–‘í•œ ìˆ˜ì˜ ìš”ì†Œë¥¼ ê°€ì§„ í…ì„œë¥¼ "ë¹„ì •í˜•(ragged)"ì´ë¼ê³  í•©ë‹ˆë‹¤. ë¹„ì •í˜• ë°ì´í„°ì—ëŠ” tf.ragged.RaggedTensorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ë¹„ì •í˜• í…ì„œëŠ” ì •ê·œ í…ì„œë¡œ í‘œí˜„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

```
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]
```

```
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

```
ValueError: Can't convert non-rectangular Python sequence to Tensor.
```

ëŒ€ì‹  tf.ragged.constantë¥¼ ì‚¬ìš©í•˜ì—¬ tf.RaggedTensorë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

```
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```

```
tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]
```

```
print(ragged_tensor.shape)
```

```
(4, None)
```

### ë¬¸ìì—´ í…ì„œ
tf.stringì€ dtypeì´ë©°, í…ì„œì—ì„œ ë¬¸ìì—´(ê°€ë³€ ê¸¸ì´ì˜ ë°”ì´íŠ¸ ë°°ì—´)ê³¼ ê°™ì€ ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë¬¸ìì—´ì€ ì›ìì„±ì´ë¯€ë¡œ Python ë¬¸ìì—´ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì¸ë±ì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ìì—´ì˜ ê¸¸ì´ëŠ” í…ì„œì˜ ì¶• ì¤‘ì˜ í•˜ë‚˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ë¬¸ìì—´ì„ ì¡°ì‘í•˜ëŠ” í•¨ìˆ˜ì— ëŒ€í•´ì„œëŠ” tf.stringsë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

ë‹¤ìŒì€ ìŠ¤ì¹¼ë¼ ë¬¸ìì—´ í…ì„œì…ë‹ˆë‹¤.

```
# Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```

```
tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```

ë¬¸ìì—´ì˜ ë²¡í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```
# If you have three string tensors of different lengths, this is OK.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# Note that the shape is (3,). The string length is not included.
print(tensor_of_strings)
```

```
tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
```

ìœ„ì˜ ì¶œë ¥ì—ì„œ b ì ‘ë‘ì‚¬ëŠ” tf.string dtypeì´ ìœ ë‹ˆì½”ë“œ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼ ë°”ì´íŠ¸ ë¬¸ìì—´ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. TensorFlowì—ì„œ ìœ ë‹ˆì½”ë“œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìì„¸í•œ ë‚´ìš©ì€ ìœ ë‹ˆì½”ë“œ íŠœí† ë¦¬ì–¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

ë¬¸ìì—´ì´ ìˆëŠ” ì¼ë¶€ ê¸°ë³¸ í•¨ìˆ˜ëŠ” tf.stringsì„ í¬í•¨í•˜ì—¬ tf.strings.splitì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
# We can use split to split a string into a set of tensors
print(tf.strings.split(scalar_string_tensor, sep=" "))
```

```
tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)
```

```
# ...but it turns into a `RaggedTensor` if we split up a tensor of strings,
# as each string might be split into a different number of parts.
print(tf.strings.split(tensor_of_strings))
```

```
tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]
```

```
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))
```

```
tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)
```

tf.castë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ í…ì„œë¥¼ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ë°”ì´íŠ¸ë¡œ ë³€í™˜í•œ ë‹¤ìŒ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
byte_strings = tf.strings.bytes_split(tf.constant("Duck"))
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8)
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)
```

```
Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)
Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)
```

```
# Or split it up as unicode and then decode it
unicode_bytes = tf.constant("ã‚¢ãƒ’ãƒ« ğŸ¦†")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)
```

```
Unicode bytes: tf.Tensor(b'\xe3\x82\xa2\xe3\x83\x92\xe3\x83\xab \xf0\x9f\xa6\x86', shape=(), dtype=string)

Unicode chars: tf.Tensor([b'\xe3\x82\xa2' b'\xe3\x83\x92' b'\xe3\x83\xab' b' ' b'\xf0\x9f\xa6\x86'], shape=(5,), dtype=string)

Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)
```

tf.string dtypeì€ TensorFlowì˜ ëª¨ë“  ì›ì‹œ ë°”ì´íŠ¸ ë°ì´í„°ì— ì‚¬ìš©ë©ë‹ˆë‹¤. tf.io ëª¨ë“ˆì—ëŠ” ì´ë¯¸ì§€ ë””ì½”ë”© ë° csv êµ¬ë¬¸ ë¶„ì„ì„ í¬í•¨í•˜ì—¬ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ë°”ì´íŠ¸ì—ì„œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### í¬ì†Œ í…ì„œ
ë•Œë¡œëŠ” ë§¤ìš° ë„“ì€ ì„ë² ë“œ ê³µê°„ê³¼ ê°™ì´ ë°ì´í„°ê°€ í¬ì†Œí•©ë‹ˆë‹¤. TensorFlowëŠ” tf.sparse.SparseTensor ë° ê´€ë ¨ ì—°ì‚°ì„ ì§€ì›í•˜ì—¬ í¬ì†Œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
```
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# We can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))
```

```
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
```
